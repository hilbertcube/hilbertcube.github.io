---
/**
 * src/pages/articles/accelerating-feature-extraction-and-image-stitching-algorithm/index.astro
 * =============================================================================================
 * Article: Accelerating Feature Extraction and Image Stitching Algorithm Using Nvidia CUDA
 * Migrated from /articles/accelerating-feature-extraction-and-image-stitching-algorithm/index.html
 */
import BaseLayout from "../../../layouts/BaseLayout.astro";
import HighlightsAndAttribute from "../../../components/HighlightsAndAttribute.astro";
---

<BaseLayout
  title="Accelerate ORB with CUDA"
  description="Accelerating Feature Extraction and Image Stitching Algorithm using Nvidia CUDA"
  keywords="image stitching, CUDA, MPI, openmp, image processing, parallel processing, multi-core, multi-threads"
>
  <Fragment slot="head">
    <style>
      .front-img {
        display: block;
        width: 100%;
        border-radius: 10px;
        height: auto;
        margin: auto;
      }
      #flowchart-caption {
        width: 70%;
      }
      @media all and (max-width: 580px) {
        #flowchart-caption {
          width: 100%;
        }
      }
    </style>
  </Fragment>

  <Fragment slot="sidebar">
    <div class="toc">
      <header class="major">
        <h2>Table of Contents</h2>
      </header>
      <ul>
        <li>
          <a href="#feature-extraction"
            >Feature Extraction from Images and the ORB Feature Detector</a
          >
          <ul>
            <li><a href="#Introduction">Introduction</a></li>
            <li><a href="#utilizing-gpu">Project's Objective</a></li>
          </ul>
        </li>
        <li>
          <a href="#literature-review">Literature Review and Technologies</a>
          <ul>
            <li><a href="#mpi">Message Passing Interfaces (MPI)</a></li>
            <li><a href="#openmp">Open Multi-Processing (OpenMP)</a></li>
            <li>
              <a href="#sift-and-orb">The SIFT and ORB Feature Detectors</a>
            </li>
            <li>
              <a href="#gpu-and-cuda"
                >Overview of General GPU Architecture and Nvidia's Compute
                Unified Device Architecture (CUDA)</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="#implementation">Implementations</a>
          <ul>
            <li><a href="#workflow">Image Stitching Workflow</a></li>
            <li><a href="#optimization">Optimization</a></li>
          </ul>
        </li>
        <li><a href="#benchmarks">Data Collection and Benchmarks</a></li>
        <li>
          <a href="#results">Results</a>
          <ul>
            <li><a href="#performance-metrics">Performance Metrics</a></li>
            <li><a href="#runtime">Runtime Comparison</a></li>
            <li><a href="#speedup">Speedup</a></li>
            <li><a href="#cost">Cost</a></li>
            <li><a href="#efficiency">Efficiency</a></li>
          </ul>
        </li>
        <li><a href="#future-work">Ending Remarks and Future Work</a></li>
        <li><a href="#References">References</a></li>
      </ul>
    </div>
    <div class="highlights-and-attribute">
      <HighlightsAndAttribute />
    </div>
  </Fragment>

  <div class="mathjax-definition">
    \[ \newcommand&#123;\lbrac&#125;&#123;\left(&#125;
    \newcommand&#123;\rbrac&#125;&#123;\right)&#125; \]
  </div>

  <div class="content-grid">
    <header>
      <div class="topic">
        Topics: C++, OpenCV, CUDA, MPI, OPENMP, Image Stitching
      </div>
      <h1 class="title">
        Accelerating Feature Extraction and Image Stitching Algorithm Using
        Nvidia CUDA
      </h1>
      <div class="date"></div>
      <figure style="margin: 0;">
        <img
          class="front-img"
          src="/articles/accelerating-feature-extraction-and-image-stitching-algorithm/banner.webp"
          alt="image"
        />
      </figure>
      <div class="Quote">
        <div class="Quote-content">
          &#8220;The images attempt to capture scientific thought. They
          represent the physical manifestation of the thought process.
          Everything in the laboratory is a product of a stream of conscious or
          unconscious thought.&#8221;
        </div>
        <div class="Author">- Peter Fraser</div>
      </div>
    </header>

    <section id="feature-extraction">
      <h2>Feature Extraction from Images and the ORB Feature Detector</h2>
      <section id="Introduction">
        <h3>Introduction</h3>
        <p>
          Assuming that you are in a region where natural disasters rampage.
          Landscape can change, buildings can collapse, and outdated map
          requires immediate, detailed, and accurate updates. This problem can
          be addressed by using Unmanned Aerial Vehicle(s) (UAV) to capture
          images of the area, and then stitch them together using existing
          computer-vision technologies. The true issue lies in how fast we can
          do this, as accurate updates mean that multiple high-quality images
          will be processed, and thus slows down the process due to highly
          expensive computational processes. One option is multi-core and
          multi-threads processing. But can we do better? The answer is yes,
          through the modern architecture behind the Graphic Processing Unit
          (GPU).
        </p>

        <div class="two-columns-block">
          <div>
            <p>
              Image stitching requires feature detection algorithms. The first
              widely-used feature detection algorithm was the Harris Corner
              Detector, introduced in 1988 by Chris Harris and Mike Stephens.
              Later on, in 1999, the Scale-invariant feature transform (SIFT)
              algorithm by David G. and Lowe revolutionized the field of
              computer vision by providing a reliable method for feature
              detection and description. It builds upon the Harris Corner
              Detector but adds many key innovations to improve robustness and
              functionality. The SIFT algorithm is still widely used today, and
              most papers regarding new methods in feature detection, either
              through traditional means, or neural networks, use SIFT as their
              benchmark.
            </p>
            <p>
              Although SIFT is a reliable method for such tasks, it is also very
              computationally expensive. Therefore, many more methods throughout
              the years have been developed to address that issue, and in 2011,
              Oriented FAST and Rotated BRIEF (ORB) was introduced. After
              multiple benchmark tests, ORB has been proven to have better
              overall performance with quick computing and is demonstrated to be
              robust to light and rotational shifts.
            </p>
          </div>
          <div>
            <figure>
              <img
                src="/articles/accelerating-feature-extraction-and-image-stitching-algorithm/capital.jpg"
                alt="Capitol Building"
                class="image-block"
                style="width: 100%"
              />
              <figcaption>
                The United States Capitol, Washington D.C., United States.
                Feature detection using the Oriented FAST and Rotated BRIEF
                (ORB) Algorithm. The colored circular regions are called key
                points of the image.
              </figcaption>
            </figure>
          </div>
        </div>
      </section>

      <section id="utilizing-gpu">
        <h3>Project's Objective</h3>
        <div class="two-columns-block">
          <div>
            <p>
              This project mainly focuses on images captured by Unmanned Aerial
              Vehicles (UAV), the image patch is then sent to a central computer
              with an Nvidia graphic card for image processing. The map
              generation process involves processing a pair of images, then the
              algorithm will detect, and match each of the key points from one
              image to another. The existing work of this project involves an
              algorithm to process the image patch using multi-core CPUs, which
              are available on most modern computers.
            </p>

            <p>
              The original author of the project, my mentor, also addressed the
              issue of increasing data overhead by employing distributed and
              shared memory architectures to reduce computation time, or in
              other words, multi-threading. For this project, we will employ all
              the previously mentioned techniques, but we will also integrate
              the Graphic Processing Unit through the use of CUDA. The goal is
              to generate reliable maps and accelerate image stitching
              algorithms even further by utilizing multi-core, multi-threads,
              and GPU computation. Performance is a large emphasis for this
              project; therefore, C++ will be prioritized instead of Python.
            </p>
          </div>
          <div>
            <figure>
              <img
                src="/articles/accelerating-feature-extraction-and-image-stitching-algorithm/30_images.webp"
                alt="30 images"
                class="image-block"
                style="width: 98%"
              />
              <figcaption>Patch of 30 images captured by the UAV</figcaption>
            </figure>

            <figure>
              <img
                src="/articles/accelerating-feature-extraction-and-image-stitching-algorithm/banner.webp"
                alt="Final Map"
                class="image-block"
                style="width: 95%"
              />
              <figcaption>Final Map Obtained from Stitching Process</figcaption>
            </figure>
          </div>
        </div>
      </section>
    </section>

    <section id="literature-review">
      <h2>Tools and Frameworks</h2>
      <section id="mpi">
        <h3>Distributed Memory Design: Message Passing Interfaces (MPI)</h3>
        <p>
          What is an MPI? Simply put, an MPI is a software designed to allow
          communication between CPU cores. MPI defines the syntax and semantics
          of library routines that allow programs to communicate data by passing
          messages between processes or cores. Here's how it works:
        </p>
        <p>
          Under the distributed memory design, each process has its own memory
          space and executes independently from other processes. This allows
          each node (processor core, or cluster of processor cores) to work on a
          subsection of the larger composite image asynchronously. To
          communicate with each other, each node is assigned a label (also
          called 'rank') which is used to send and receive information to/from
          other nodes. An MPI is simply a portable distributed-memory framework
          to employ this design. It should be noted that the while the terms
          node, process, and processor are used interchangeably, the algorithm
          does support nodes that consist of multiple processor cores. For this
          research project, we will be using the Microsoft Message Passing
          Interface (Ms.MPI).
        </p>
      </section>

      <section id="openmp">
        <h3>Shared Memory Design: Open Multi-Processing (OpenMP)</h3>
        <p>
          OpenMP is an Application Program Interface (API) that may be used to
          direct multi-threaded, shared memory parallelism in C/C++, or Fortran
          programs. Both g++ (available since GCC 4.9) and MSVC compiler have
          OpenMP available through the header <code class="inline-code"
            >#include&lt;omp.h&gt;</code
          >. To enable OpenMP in Microsoft Visual Studio, go to Project &gt;
          Properties &gt; C/C++ &gt; Language &gt; OpenMP support, select yes.
          For g++, you must add <code class="inline-code">-fopenmp</code> to the compilation
          of any module that uses OpenMP:
        </p>
        <div style="text-align: center; margin: 25px 0;  overflow: auto;">
          <pre
            class="console"
            style="display:inline-block;"><samp>    g++ -c test.cpp -o test.o -fopenmp
    g++ test.o -o test -fopenmp -lpthread    </samp></pre>
        </div>
        <p>
          What's the difference between this and the stl threads, or unix
          pthreads? Not that much differences, but OpenMP are usually used in
          loops for acceleration.
        </p>
      </section>

      <section id="sift-and-orb">
        <h3>The SIFT and ORB Feature Detectors</h3>
        <p>
          <strong>Scale-Invariant Feature Transform.</strong> SIFT is (probably) one
          of the most well-known and reliable feature detectors in the field of computer
          vision to extract invariant features from an image. SIFT primarily works
          based on the Difference of Gaussian (D.o.G), defined as
        </p>
        <div class="equation">
          \begin&#123;equation&#125; D(\mathbf&#123;x&#125;,\sigma) =
          \frac&#123;1&#125;&#123;2\pi\sigma&#125;\left[\frac&#123;1&#125;&#123;k&#125;\exp\lbrac-\frac&#123;\lVert\mathbf&#123;x&#125;\rVert^2&#125;&#123;2(k\sigma)^2&#125;\rbrac
          -
          \exp\lbrac-\frac&#123;\lVert\mathbf&#123;x&#125;\rVert^2&#125;&#123;2\sigma^2&#125;\rbrac
          \right]. \end&#123;equation&#125;
        </div>
        <p>Since</p>
        <div class="equation">
          \begin&#123;equation&#125; D(\mathbf&#123;0&#125;,\sigma) =
          \frac&#123;1&#125;&#123;2\pi k \sigma&#125; &lt;
          \frac&#123;1&#125;&#123;\sqrt&#123;2&#125;&#125;D_&#123;max&#125;\quad\text&#123;and&#125;\quad
          D(\mathbf&#123;\infty&#125;,\sigma)=0, \end&#123;equation&#125;
        </div>
        <p>
          the D.o.G is a bandpass filter, which means that it only lets selected
          frequencies through. One characteristic of the bandpass filter is that
          it lets frequencies greater than
          $\frac&#123;1&#125;&#123;\sqrt&#123;2&#125;&#125;D_&#123;max&#125;$
          through and blocks low frequencies. This means that the frequencies
          that it passes tend to be the areas of high contrast on the image,
          which are usually edges (In computer vision, edges are abrupt changes
          in intensity, discontinuity in image brightness, or contrast).
        </p>
        <p>
          The algorithm then uses the Gaussian pyramid to compare the respective
          pixel with its surrounding 26 other neighbor pixels to look for the
          extrema of the image and improve the accuracy by the Taylor series
          method. SIFT then uses a straightforward approach for assigning
          orientations. For each image sample, $L(x,y)$, we compute the gradient
          magnitude $M(x,y)$ and orientation angle $\theta(x,y)$ using
          differences of pixels:
        </p>
        <div class="equation">
          \begin&#123;equation&#125; M(x,y) = \sqrt&#123;(L(x+1, y) -
          L(x-1,y))^2 + (L(x,y+1) - L(x,y-1))^2&#125; \end&#123;equation&#125;
        </div>
        <p>and,</p>
        <div class="equation">
          \begin&#123;equation&#125; \theta(x,y) =
          \tan^&#123;-1&#125;\lbrac\frac&#123;L(x,y+1) -
          L(x,y-1)&#125;&#123;L(x+1, y) - L(x-1,y)&#125;\rbrac.
          \end&#123;equation&#125;
        </div>
        <p>
          The final output is an $n$-dimensional feature vector whose elements
          are invariant feature descriptors. In 2018, authors Griwodz, Calvet,
          and Halvorsen proposed a Python library called PopSIFT, which serves
          as a CUDA implementation of the SIFT algorithm.
        </p>

        <p style="margin-top: 30px">
          <strong>Oriented FAST and Rotated BRIEF.</strong>
          FAST, short for &#8220;Features from Accelerated Segment Test,&#8221; is
          a widely recognized corner detection algorithm introduced by Edward Rosten
          and Tom Drumm in their paper &#8220;Machine Learning for High-speed Corner
          Detection.&#8221; FAST identifies corners by examining a circular region
          around a pixel to determine if the pixel qualifies as a corner. The ORB
          (Oriented FAST and Rotated BRIEF) algorithm uses FAST-9, which uses a circle
          with a radius of 9 pixels to optimize performance. However, because the
          original FAST algorithm does not account for orientation, ORB enhances it
          by assigning an orientation to each detected keypoint (similar to SIFT),
          thereby making the algorithm rotation-invariant. This orientation is calculated
          using the intensity centroid method, which leverages the moments of the
          patch around the keypoint, defined as:
        </p>
        <div class="equation">
          \begin&#123;equation&#125; m_&#123;pq&#125; =
          \sum_&#123;x,y&#125;x^py^qI(x,y) \end&#123;equation&#125;
        </div>
        <p>
          These moments are used to determine the dominant orientation of the
          keypoint. The centroid can be then computed by
        </p>
        <div class="equation">
          \begin&#123;equation&#125; C =
          \lbrac\frac&#123;m_&#123;10&#125;&#125;&#123;m_&#123;00&#125;&#125;,\frac&#123;m_&#123;01&#125;&#125;&#123;m_&#123;00&#125;&#125;\rbrac
          \end&#123;equation&#125;
        </div>
        <p>
          By optimizing the BRIEF (Binary Robust Independent Elementary
          Features) algorithm, binary descriptors are generated by simple pixel
          intensity comparison, and Angle invariance is recognized by shifting
          the descriptors in the main direction.
        </p>
      </section>

      <section id="gpu-and-cuda">
        <h3>
          Overview of General GPU Architecture and Nvidia's Compute Unified
          Device Architecture (CUDA)
        </h3>
        <p>
          Unlike a Central Processing Unit (CPU), which typically has only a few
          physical cores, a Graphics Processing Unit (GPU) can contain thousands
          or even tens of thousands of cores. Although GPU cores are designed
          for simple calculations and are less versatile than CPU cores, the
          GPU's key advantage lies in its ability to perform large-scale
          parallel computations. Take a look at an image, for instance:
        </p>
        <figure>
          <img
            src="/articles/accelerating-feature-extraction-and-image-stitching-algorithm/pixels.jpg"
            alt="Zooming into pixels"
            class="image-block"
            style="width: 55%"
          />
          <figcaption>
            Zooming into an image. Image by Julie Waterhouse Photography
          </figcaption>
        </figure>

        <p>
          Images are composed of millions of pixels. When processing an image,
          the GPU cannot handle pixels one by one (it shouldn't!), as doing so
          would leave many cores idle, leading to a significant waste of
          resources. Instead, a key principle of GPU operation is parallelism:
          whichever core is available first takes on the computation, ensuring
          that all cores are utilized efficiently. All computations are
          independent of each other, and finally, we only need to combine them
          to output the final input image.
        </p>
        <p>
          Let's say we have 100 tasks for a GPU to compute, with each task
          represented as a thread. GPUs are designed to handle thousands or even
          millions of threads simultaneously, but they don't assign one thread
          to each core directly. Instead, GPU cores are organized into groups
          called "warps," typically consisting of 32 threads that execute the
          same instruction simultaneously. These warps are managed by units
          within the GPU called Streaming Multiprocessors (SMs).
        </p>
        <p>
          If the number of tasks increases to 1 million, the GPU doesn't need 1
          million cores to process them. Instead, it groups the threads into
          blocks, and these blocks are distributed among the SMs. Each SM
          contains multiple cores that work together to execute the warps of
          threads. When an SM processes a block, it schedules the warps
          dynamically, keeping all its cores busy and switching between warps to
          hide any delays, such as waiting for memory access. For example, with
          1,000 cores organized into several SMs, each SM might handle many
          blocks of threads. Even if a single block contains 1,000 threads, the
          SM can manage them efficiently by processing them in warps and
          switching between them as needed. This hierarchical structure allows
          the GPU to handle a vast number of threads, ensuring that even with
          millions of tasks, the cores are utilized efficiently to maximize
          parallel computation.
        </p>
      </section>
    </section>

    <section id="implementation">
      <h2>Implementations</h2>
      <section id="workflow">
        <h3>Image Stitching Workflow</h3>
        <p>
          The code base of this project belongs to a private repository, so I
          will not put the full code on here. It wouldn't make much sense anyway
          because this whole process spans across thousands of lines code.
          Instead, I will be summarizing the image stitching process using the
          flow chart below:
        </p>
        <figure>
          <img
            src="/articles/accelerating-feature-extraction-and-image-stitching-algorithm/flowchart.webp"
            alt="Final Map"
            class="image-block"
            style="width: 90%"
          />
          <figcaption id="flowchart-caption">
            Image Stitching workflow. Green are the steps that can be further
            accelerated with CUDA, and blue are steps that can be further
            accelerated with OpenMP.
          </figcaption>
        </figure>
        <p>
          In order to further improve the speed of image processing, the author
          of the CPU implementation used a distributed memory design to
          parallelize image processing. Distributed memory designs transfer
          information between multiple CPU cores through MPI, with each or more
          CPU cores processing two images as a node. The greater the number of
          CPU cores, the greater the number of images that can be processed
          simultaneously in parallel without the need to wait for earlier images
          in the list to complete processing before processing later images. For
          example, if one wishes to concatenate four images, one can use two CPU
          cores for parallel processing.
        </p>
        <p>
          When the two nodes are finished processing, the results are sent to
          the new node via MPI to process the two images processed by the
          previous node. This structure is similar to the tree structure and has
          been shown to increase the computation speed. However, one needs to
          note that given an unlimited amount of resources, it does not
          necessarily mean that the program can speed up infinitely, see <a
            href="https://en.wikipedia.org/wiki/Amdahl%27s_law"
            class="url">Amdahl's law</a
          >, which states that the potential speedup of a process due to
          parallelization is limited by the portion of the process that cannot
          be parallelized, which can be formalized by the equation
        </p>
        <div class="equation">
          \begin&#123;equation&#125; S = \frac&#123;1&#125;&#123;(1-P) +
          \frac&#123;P&#125;&#123;N&#125;&#125;, \end&#123;equation&#125;
        </div>
        <p>
          where $S$ is the speedup ratio, $P$ is the proportion of the task that
          can be parallelized, $N$ is the number of processors or cores, and
          $(1-P)$ is the proportion of the task that must be performed
          sequentially.
        </p>
      </section>

      <section id="optimization">
        <h3>Optimization</h3>
        <p>
          The main change from the original paper is to convert the method of
          image feature extraction using CPU to GPU. We will add a function
          based on the code of the original paper that can detect image features
          using the GPU. We changed the finder of feature detection to use <code
            class="inline-code">cuda::ORB</code
          >, and based on the open source code of OpenCV CUDA, we used the
          corresponding CUDA ORB image feature detection algorithm to achieve
          the same purpose as its regular version. We call this new function
        </p>

        <div style="text-align: center; margin: 25px 0;  overflow: auto;">
          <pre
            class="console"
            style="display:inline-block;"><samp>    void computeImageFeatures(Ptr&lt;cuda::ORB&gt; orb, const cuda::GpuMat&amp; img,ImageFeatures&amp; features)    </samp></pre>
        </div>
        <p>
          to compute GPU images. This is an analogous version of the <code
            class="inline-code">detectAndCompute</code
          >
          function when using regular feature detector ORB. The key feature in this
          function is the computation of descriptors on the GPU. To do this, we must
          upload the descriptors from the CPU to the GPU, and then download it back
          to the CPU.
        </p>
        <div class="box">
          <div class="code-container">
            <button class="copy-btn">Copy</button>
            <pre
              class="line-numbers"><code class="language-cpp">// A peak inside computeImageFeatures()

cuda::GpuMat keypointsGPU;
orb-&gt;detectAndComputeAsync(grayImg, cuda::GpuMat(), keypointsGPU, descriptorsGPU);
cuda::Stream::Null().waitForCompletion(); 

// Convert GPU keys to CPU keys
vector&lt;KeyPoint&gt; keypointsCPU;
orb-&gt;convert(keypointsGPU, keypointsCPU);

if (keypointsCPU.empty()) &#123;
    LOGLN("No keypoints detected on GPU");
    throw std::runtime_error("No keypoints detected on GPU");
&#125;
cerr "Keypoints detected on GPU: " &lt;&lt; keypointsCPU.size() &lt;&lt; endl;

if (descriptorsGPU.empty()) &#123;
    LOGLN("Descriptor computation failed on GPU");
    throw std::runtime_error("Descriptor computation failed on GPU");
&#125;
LOGLN("Descriptors computed on GPU: " &lt;&lt; descriptorsGPU.size());

// Download descriptors from GPU to CPU
descriptorsGPU.download(descriptors);

if (descriptors.empty()) &#123;
    LOGLN("Failed to download descriptors from GPU to CPU");
    throw std::runtime_error("Failed to download descriptors from GPU to CPU");
&#125;
LOGLN("Descriptors downloaded to CPU: " &lt;&lt; descriptors.size());

// Ensure the number of keypoints and descriptors is consistent
if (keypointsCPU.size() != descriptors.rows) &#123;
    cerr &lt;&lt; "Mismatch in keypoints and descriptors count: Keypoints = " &lt;&lt; keypointsCPU.size()
        &lt;&lt; ", Descriptors = " &lt;&lt; descriptors.rows &lt;&lt; endl;
    throw std::runtime_error("Mismatch in keypoints and descriptors count");
&#125;

// Store detected features and descriptors
features.keypoints = keypointsCPU;
features.descriptors = descriptors;
features.img_size = grayImg.size();</code></pre>
          </div>
        </div>
      </section>
    </section>

    <section id="benchmarks">
      <h2>Data Collection and Benchmarks</h2>
      <h3>System Specs</h3>
      <div class="table-wrapper">
        <table
          style="margin-left: auto; margin-right: auto; text-align: center; min-width: 90%;"
          id="setup-table"
        >
          <tr
            style="border-top: 2px solid var(--grid-text-color); border-bottom: 1px solid var(--grid-text-color);"
          >
            <th></th>
            <th style="border-left: 1px solid var(--grid-text-color)"
              ><strong>First Setup</strong></th
            >
            <th><strong>Second Setup</strong></th>
            <th><strong>Third Setup</strong></th>
            <th><strong>Fourth Setup</strong></th>
          </tr>
          <tr style="border: 0; ">
            <td>CPU</td>
            <td style="border-left: 1px solid var(--grid-text-color)"
              >Intel Core i7-8750H</td
            >
            <td>Intel Core i9-13900KF</td>
            <td>Intel Core i7-7700k</td>
            <td>Intel Xeon Gold</td>
          </tr>
          <tr>
            <td>GPU</td>
            <td style="border-left: 1px solid var(--grid-text-color)"
              >NVIDIA GTX 1070 Max-Q</td
            >
            <td>NVIDIA RTX 4060Ti</td>
            <td>NVIDIA GTX 1070</td>
            <td>NVIDIA Tesla-v100</td>
          </tr>
          <tr>
            <td>OpenCV Version</td>
            <td style="border-left: 1px solid var(--grid-text-color)"
              >OpenCV 4.10.0</td
            >
            <td>OpenCV 4.10.0</td>
            <td>OpenCV 4.5.5</td>
            <td>OpenCV 4.5.5</td>
          </tr>
          <tr>
            <td>RAM</td>
            <td style="border-left: 1px solid var(--grid-text-color)">16GB</td>
            <td>32GB</td>
            <td>64GB</td>
            <td>192GB</td>
          </tr>
          <tr style="border-bottom: 1px solid var(--grid-text-color);">
            <td>GPU Memory</td>
            <td style="border-left: 1px solid var(--grid-text-color)">8GB</td>
            <td>16GB</td>
            <td>8GB</td>
            <td>16GB</td>
          </tr>
        </table>
      </div>

      <h3>CUDA-accelerated Setups</h3>
      <p>
        The data set for this project is a set of 500 4k images, but we process
        them in a patch of 64 images, each with a resolution of 3840 $\times$
        2160 px. The setups that used CUDA to accelerate the processing of these
        high-resolution images will be limited to the first and second setup.
      </p>

      <p>
        <strong>CPU Implementation.</strong> We will evaluate the algorithm's performance
        under different conditions, including with and without CUDA acceleration.
        In the absence of CUDA acceleration, we will record the impact of distributed
        memory design (utilizing MPI) and shared memory design (utilizing OpenMP)
        on the algorithm's speed. Given our limited resources, we will test the processing
        speed using 1, 2, 4, 8, 16, and 32 CPU cores, as well as using 1, 2, 4, 8,
        16, 24 threads, and 32 threads.
      </p>

      <p>
        <strong>GPU Implementation.</strong> For the CUDA-accelerated version of the
        algorithm, the tests will concentrate exclusively on the distributed memory
        design. This focus is due to the current limitations of the experiment, which
        prevent us from utilizing the GPU implementation across multiple threads.
        In simple words, OpenMP is not available for CUDA. I am still working on this
        problem.
      </p>

      <div
        class="two-columns-block"
        style="margin: 30px 0 10px; column-gap: 1.2em;"
      >
        <div>
          <span style="font-size: large;"
            ><strong>Performance Testing without CUDA Acceleration</strong
            ></span
          >
          <ul style="line-height: 1.6;">
            <li style="margin: var(--in-page-li-spacing) 0;">
              <strong>Benchmark Test:</strong> Record the processing speed of 64 images
              without any optimization, which will serve as the initial benchmark
              for the experiment.
            </li>
            <li style="margin: var(--in-page-li-spacing) 0;">
              <strong>Single-Core Execution (Serial Processing):</strong> Test the
              processing speed of 64 images using a single CPU core.
            </li>
            <li style="margin: var(--in-page-li-spacing) 0;">
              <strong>Distributed Memory Design (Parallel Processing):</strong> Test
              the processing speed for 1, 2, 4, 8, 16, and 32 CPU cores.
            </li>
            <li style="margin: var(--in-page-li-spacing) 0;">
              <strong
                >Single-Core Execution and Shared Memory Design (Serial
                Threading):</strong
              > Test the processing speed for 1, 2, 4, 8, 16, 24, and 32 threads with
              1 core.
            </li>
            <li style="margin: var(--in-page-li-spacing) 0;">
              <strong
                >Distributed Memory and Shared Memory Design (Parallel
                Processing and Multi-threading):</strong
              >
              Test the processing speed using combinations such as 2 cores 2 threads,
              2 cores 4 threads, 4 cores 2 threads, 4 cores 4 threads, etc.
            </li>
          </ul>
        </div>
        <div>
          <span style="font-size: large;"
            ><strong>Performance Testing with CUDA Acceleration</strong></span
          >
          <ul style="line-height: 1.6;">
            <li style="margin: var(--in-page-li-spacing) 0;">
              <strong>Benchmark Test:</strong> Record the processing speed of 64 images
              under the optimized design of 1 core and 1 threads with CUDA was recorded
              as the second part experimental initial benchmark.
            </li>
            <li style="margin: var(--in-page-li-spacing) 0;">
              <strong>Single-Core Execution (Serial Processing):</strong> Test the
              processing speed of 64 images using a single CPU core and GPU acceleration
              with 1 core.
            </li>
            <li style="margin: var(--in-page-li-spacing) 0;">
              <strong
                >Distributed Memory Design (Parallel Processing and
                Serial-threading):</strong
              > Test the processing speed using 1, 2, 4, 8, 16, and 24 CPU cores with
              GPU acceleration.
            </li>
          </ul>
        </div>
      </div>
    </section>

    <section id="results">
      <h2>Results</h2>
      <section id="performance-metrics">
        <h3>Performance Metrics</h3>

        <div
          class="definition"
          data-definition-name=" (Serial and Parallel Runtime)"
        >
          The serial and parallel runtime of a program are defined as follows:
          <ol type="i" style="line-height: 1.6;">
            <li style="margin: var(--in-page-li-spacing) 0;">
              The Serial runtime of a program is the time between the beginning
              and the end of its execution on a sequential processor. We denote
              this by $T_S$.
            </li>
            <li style="margin: var(--in-page-li-spacing) 0;">
              Parallel runtime is the time from the moment the first processor
              begins its execution to the moment the last processor ends its
              execution. We denote this by $T_P$.
            </li>
          </ol>
        </div>

        <div class="definition" data-definition-name=" (Speedup)">
          Speedup is defined as the ratio between the serial runtime to the time
          taken by parallel runtime,
          <div class="equation">
            \begin&#123;equation&#125; S=\frac&#123;T_S&#125;&#123;T_P&#125;
            \end&#123;equation&#125;
          </div>
          The speedup of a parallel algorithm measures how much faster an algorithm
          is than its sequential counterpart.
        </div>

        <div class="definition" data-definition-name=" (Cost)">
          The cost of processing a program on a parallel system is defined as
          the product of run time and the number of processors,
          <div class="equation">
            \begin&#123;equation&#125; C = T_P\cdot p, \end&#123;equation&#125;
          </div>
          where $p$ denotes the number of processors.
        </div>

        <div class="definition" data-definition-name=" (Efficiency)">
          The efficiency of a parallel program that uses $p$ processors is
          defined by
          <div class="equation">
            \begin&#123;equation&#125; E = \frac&#123;T_S&#125;&#123;p\cdot
            T_P&#125;=\frac&#123;S&#125;&#123;p&#125; \end&#123;equation&#125;
          </div>
        </div>
      </section>

      <section id="runtime">
        <h3>Runtime Comparison</h3>
        <p>
          As mentioned, I will compare the two runtime of the setup with, and
          without multi-threading.
        </p>
        <div class="two-columns-block">
          <div>
            <figure style="padding: 0; margin: 0;">
              <img
                src="/articles/accelerating-feature-extraction-and-image-stitching-algorithm/no_openmp.webp"
                alt="Final Map"
                class="image-block"
                style="width: 100%; padding: 0;"
              />
            </figure>
            <figcaption>Without OpenMP for CPU vs GPU (1 thread)</figcaption>
          </div>
          <div>
            <figure style="padding: 0; margin: 0;">
              <img
                src="/articles/accelerating-feature-extraction-and-image-stitching-algorithm/with_openmp.webp"
                alt="Final Map"
                class="image-block"
                style="width: 100%; padding: 0;"
              />
            </figure>
            <figcaption>With OpenMP for CPU vs GPU (1 thread)</figcaption>
          </div>
        </div>

        <p>
          I initially ran our code on Setup 1. The original goal of this
          research is to be able to stitch 64 4K images, but due to the limited
          resources of the first setup, I had to downscale the image by 75% from
          their original quality to 540$\times$960 px.
        </p>
        <p>
          The GPU implementation significantly outperformed the original
          CPU-based image stitching, reducing the runtime by a factor of three
          to four. However, as the number of used cores exceeded the available
          physical cores, the application began to slow down: all components of
          the system were operating at their limits: the CPU was running at
          100%, the RAM was fully utilized at 16GB, and the GPU memory was maxed
          out at 8GB. This likely due to the context switching that the system
          had to perform when running out of physical cores.
        </p>
        <p>
          One interesting thing for the first setup is that the GPU
          implementation was able to run up to 8 CPU cores, but the original
          implementation could only run up to 4 cores. One possible reason for
          this is that the GPU shared the resources with the CPU while
          performing the algorithm, which put less constraint on the CPU, and
          hence pushed the number of cores to the limit.
        </p>
      </section>

      <section id="speedup">
        <h3>Speedup</h3>
        <p>
          Even though the runtime has massively decreased under the usage of
          CUDA, the speedup ratio does not stand out among the CPU with the
          OpenMP dataset, but it did, however, speedup in all scenarios of cores
          against CPU with 1 thread, which is reasonable since our GPU setup
          also uses only one thread of the CPU (no OpenMP available for GPU).One
          possible reason why the GPU doesn't speed up as fast is due to the
          uploading and downloading of images to the GPU, which costs much more
          resources due to the high quality of the image patch.
        </p>
        <figure>
          <img
            src="/articles/accelerating-feature-extraction-and-image-stitching-algorithm/speedup.webp"
            alt="Final Map"
            class="image-block"
            style="width: 60%"
          />
        </figure>
      </section>

      <section id="cost">
        <h3>Cost</h3>
        <p>
          In parallel computing, resource inefficiency occurs when parts of a
          process are forced to wait for others to complete, reducing overall
          performance. As observed, the cost of the GPU implementation is much
          lower than every other previous CPU implementations. This is not a
          surprise at all, as GPUs, optimized for massively parallel tasks,
          often provide significantly better performance for certain
          applications compared to traditional CPU implementations, resulting in
          lower operational costs for these specific workloads.
        </p>
        <figure>
          <img
            src="/articles/accelerating-feature-extraction-and-image-stitching-algorithm/cost.webp"
            alt="Final Map"
            class="image-block"
            style="width: 60%"
          />
        </figure>
      </section>

      <section id="efficiency">
        <h3>Efficiency</h3>
        <p>
          For efficiency, the CUDA-enhanced algorithm is less efficient than the
          CPU with 1 thread setup, but is overall more efficient than other CPU
          setups as the number of cores increases. The efficiency of the GPU
          implementation eventually matches that of the CPU, 1 thread
          implementation as $p=32$.
        </p>
        <figure>
          <img
            src="/articles/accelerating-feature-extraction-and-image-stitching-algorithm/efficiency.webp"
            alt="Final Map"
            class="image-block"
            style="width: 60%"
          />
        </figure>
      </section>
    </section>

    <section id="future-work">
      <h2>Ending Remarks and Future Work</h2>
      <p>
        One significant drawback to the CUDA-accelerated algorithm is that it is
        a generally memory-costly method (extremely costly even, in many
        iterations of test cases). However, if the user lacks a high-quality
        camera or needs to create a map quickly without focusing on fine
        details, the image patch can be downscaled to meet these requirements.
        This approach has been validated in the first setup, where the 4K patch
        was downscaled by 75% and worked perfectly. This can be achieved easily
        by modifying a small section in the code, but this is not the main
        discussion of this article. Another issue with the 4K patch is that it
        was not able to stitch parts of the map where there are rotations due to
        memory issues. After several hours and careful inspection, it is deduced
        that this is not a problem with the code, but due to memory issues,
        since if we stitch the same patch with downscaled quality, it was able
        to stitch the patch successfully without any problem.
      </p>
      <p>
        Integrating shared memory design for multi-threading with the GPU is
        still an open problem, and I plan to address this in future projects to
        accelerate the algorithm even further. The ultimate goal of this project
        is to process 64 frames of 4K images in one second. Another objective is
        perhaps to resurvey the memory management in the code base to ensure
        that the program does not crash when the input is too large and to
        generate more consistent and reliable results.
      </p>
    </section>

    <section>
      <h2>More Articles</h2>
      <div id="rec-article-container"></div>
    </section>
  </div>

  <Fragment slot="scripts">
    <script is:inline src="/assets/js/blogpage-setting.js"></script>
    <script is:inline>
      loadDate("orb-cuda-1");
    </script>
    <script
      is:inline
      src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"
    ></script>
    <script
      is:inline
      src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-c.min.js"
    ></script>
    <script
      is:inline
      src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-cpp.min.js"
    ></script>
    <script
      is:inline
      src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/line-numbers/prism-line-numbers.min.js"
    ></script>
    <script
      is:inline
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"
      async></script>
  </Fragment>
</BaseLayout>
